{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import glob # glob API for importing list of (calibration) images\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection (object-oriented programming: line is a object)\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # True if line was detected in the frame before\n",
    "        self.detected = False # set to True when line is successfully detected\n",
    "        # x values for currently detected line pixels\n",
    "        self.current_fitx = None\n",
    "        # y values for detected line pixels\n",
    "        self.current_fity = None\n",
    "        # list of the x values of the last N fits of the line\n",
    "        self.previous_fitx = []\n",
    "        # averaged\n",
    "        self.mean_fitx = []\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_poly = [np.array([False])]\n",
    "        # best polynomial coefficients for the last iteration\n",
    "        self.prev_poly = [np.array([False])]\n",
    "\n",
    "    # function for collecting the x calues of detected lines frame by frame in order to average the previous fits\n",
    "    # this function is used for smoothing over the last N frames if line detections jump around from frame to frame (jitter)\n",
    "    def average_pre_lanes(self): \n",
    "        tmp = copy(self.previous_fitx)\n",
    "        tmp.append(self.current_fitx)\n",
    "        self.mean_fitx = np.mean(tmp, axis=0)\n",
    "\n",
    "    def append_fitx(self):\n",
    "        if len(self.previous_fitx) == N:\n",
    "            self.previous_fitx.pop(0)\n",
    "        self.previous_fitx.append(self.mean_fitx)\n",
    "\n",
    "    def process(self, ploty):\n",
    "        self.current_fity = ploty\n",
    "        self.average_pre_lanes()\n",
    "        self.append_fitx()\n",
    "        self.prev_poly = self.current_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating lines (objects) with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for monitoring characteristics of detected lines and sanity check them later\n",
    "\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "\n",
    "N = 5 # number of previous lines to monitor. Needed for smoothing and computing average fit over last N frames\n",
    "LANEWIDTH = 3.7  # highway lane width in US: 3.7 meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source points in the original image that will be warped\n",
    "src = np.float32([[  100.,   719.],  # Links unten\n",
    "                  [  542.,   470.],  # Links oben\n",
    "                  [  738.,   470.],  # Rechts oben\n",
    "                  [ 1180.,   719.]]) # Rechts unten\n",
    "'''\n",
    "    \n",
    "#source points for A99Munich test video\n",
    "src = np.float32([[  235.,   719.], \n",
    "                  [  580.,   536.],\n",
    "                  [  688.,   536.],\n",
    "                  [ 1003.,   719.]])\n",
    "'''                  \n",
    "\n",
    "# destination points in the target image (after warping)  \n",
    "dst = np.float32([[ 200.,  720.],\n",
    "                  [ 200.,    0.],\n",
    "                  [ 1080.,    0.],\n",
    "                  [ 1080.,  720.]])\n",
    "  \n",
    "        \n",
    "# use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32) \n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # nx=9 and ny=6\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg') # importing the glob API\n",
    "\n",
    "# Step through the list and search for chessboard corners and if found, add object and image points (needed later in cv.calibrateCamera())\n",
    "for fname in images:\n",
    "    img = plt.imread(fname)\n",
    "    # no cv2.undistort(img, mtx, dist, None) here because cal images are not distorted (only the first one a little bit maybe)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # why? to find corners easily in the next step\n",
    "                                                # if you are using cv2.imread() or the glob API, as happens here,\n",
    "                                                # this will read in a BGR image and you should convert to grayscale\n",
    "                                                # using cv2.COLOR_BGR2GRAY.\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None) # nx=9 and ny=6 (ret=return)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp) # für jedes Bild in der for-Schleife wird dasselbe array (objp) hinzugefügt\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners (this is not necessary but helpful for demonstration purposes)\n",
    "        # img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        # plt.imshow(img)\n",
    "\n",
    "# Perform camera calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions (for both pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes an image, object points, and image points, performs the camera calibration, image distortion correction\n",
    "# and returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)  # undist war im Kurs dst (destination)\n",
    "    return undist\n",
    "\n",
    "def warp(img, M):\n",
    "\n",
    "    # Compute and apply perspective transform\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)  # keep same size as input image\n",
    "\n",
    "    return warped\n",
    "\n",
    "# thresholding means as much as creating a binary by means of thresholds\n",
    "def threshold(img, s_thresh=(170, 255), sx_thresh=(20, 100), thresh=(20, 100)):\n",
    "    \n",
    "    # Grayscale image? No! Why? Single color needed to calculate derivatives >> \"single color\" can also mean h-/l- or s-channel! \n",
    "    # We already saw that standard grayscaling lost color information for the lane lines. This is why we do not grayscale.\n",
    "    # Exploring gradients in other colors spaces / color channels shows that l-channel works better\n",
    "    \n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # threshold gradient\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize) # Sobel x (identifies vertical edges)\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize)\n",
    "    #grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "    gradient_thresholded = np.zeros_like(dir_binary)\n",
    "    gradient_thresholded[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack((np.zeros_like(gradient_thresholded), gradient_thresholded, s_binary)) * 255\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(gradient_thresholded)\n",
    "    combined_binary[(s_binary == 1) | (gradient_thresholded == 1)] = 1\n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "\n",
    "## start: functions for gradient threshold\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(20, 100)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    \n",
    "    # Grayscale image? No! Why? Single color needed to calculate derivatives >> \"single color\" can also mean h-/l- or s-channel! \n",
    "    # We already saw that standard grayscaling lost color information for the lane lines. This is why we do not grayscale.\n",
    "    # Exploring gradients in other colors spaces / color channels shows that other channels might work better\n",
    "    \n",
    "    # instead taking hsv color space\n",
    "    #hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    #h_channel = hsv[:,:,0]\n",
    "    #s_channel = hsv[:,:,1]\n",
    "    #v_channel = hsv[:,:,2]\n",
    "    \n",
    "    # instead taking hls color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # 2) Calculate the derivative in x or y given orient = 'x' or 'y' and\n",
    "    # 3) take the absolute\n",
    "    if orient == \"x\":\n",
    "        sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobel = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    else:\n",
    "        sobely = cv2.Sobel(l_channel, cv2.CV_64F, 0, 1)\n",
    "        abs_sobel = np.absolute(sobely) # absolute value image\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Threshold: Create a mask of 1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1   \n",
    "    \n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    return dir_binary\n",
    "\n",
    "## end: functions for gradient threshold\n",
    "\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    \n",
    "    '''\n",
    "    Findet mit der sliding windows Methode die Pixel im binary_warped, die zu den Spurlinien gehören und gibt sie wie folgt aus:\n",
    "    \n",
    "    leftx >> [308 309 310 ...362 363 364] Liste der x-Koordinaten von Pixeln, die zur left lane gehören müssten\n",
    "    lefty >> [640 640 640 ... 159 159 159] List der y-Koordinaten von Pixeln, die zur right lane gehören müssten\n",
    "    rightx >> []\n",
    "    righty >> []\n",
    "    \n",
    "    Außerdem werden auf das Input-Bild die sliding windows (grüner Rahmen) gezeichnet.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    \n",
    "    '''\n",
    "    Die Polynomfunktion wird ermittelt (np.polyfit()) und die sich daraus ergebende Linie gelb eingezeichnet in das Input-image.\n",
    "    Außerdem werden die zu Beginn der function ermittelten lane pixels rot (left lane) bzw. blau (right lane) eingefärbt.\n",
    "    (Das Zeichnen der windows (grüner Rahmen) geschieht in der function find_lane_lines, die die sliding windows Methode nutzt.)\n",
    "    \n",
    "    \n",
    "    Mit Hilfe der Pixel, die zu den lane lines gehören (diese werden durch Aufruf der Funktion find_lane_lines()\n",
    "    separat ermittelt; Ergebnis z.B. leftx >> Liste mit den x-Koordinaten der left lane),\n",
    "    wird eine passende Polynomfunktion x = A*y**2 + B*y + C ermittelt (\"gefittet\"). Dabei sind:\n",
    "        \n",
    "        left_fit >> [A B C] Polynomkoeffizienten\n",
    "        right_fit >> dito\n",
    "        \n",
    "        ploty >> z.B. [0 1 2 3 4 ... 717 718 719] y-Koordinaten des Polynoms bzw. der sich daraus ergebenden Linie\n",
    "        \n",
    "        left_fitx >> z.B. [375 374,8 374,65 374,48 ... 319] x-Koordinaten des Polynoms bzw. der sich daraus ergebenden Kurve\n",
    "                  >> errechnet sich aus A*y**2 + B*y + C mit y = ploty\n",
    "        right_fitx >> dito\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2) # left_fit beinhaltet die Koeffizienten A, B und C\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0]) # ploty ist eine Liste von [0 1 2 .... 719]\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] # left_fitx ist die gesamte Funktion (x = A*y**2 + B*y + C) des gefundenen, passenden Polynoms \"fit\"\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0] # Pixel der left line werden rot dargestellt, Pixel der right line blau\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow') # x-Koordinaten des Polynoms (left_fitx) und y-Koordinaten des Polynoms (ploty) zum Plotten\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    #return out_img, left_fit, right_fit, ploty\n",
    "    return left_fit, right_fit\n",
    "\n",
    "def search_around_poly(left_fit, right_fit, binary_warped):\n",
    "    \n",
    "    # width of the margin around the previous polynomial to search\n",
    "    margin = 50\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    #Set the area of search based on activated x-values within the +/- margin of our polynomial function\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    " \n",
    "    # fit new polynomials\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit\n",
    "\n",
    "def measure_curvature_real(ploty, leftx, rightx):\n",
    "    \n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    \n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Convert polynomials to real world\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return (left_curverad+right_curverad)/2.0\n",
    "\n",
    "def off_center(left, mid, right):\n",
    "    \"\"\"\n",
    "    :param left: left line position\n",
    "    :param mid:  car position\n",
    "    :param right: right line position\n",
    "    :return: True or False, indicator of off center driving\n",
    "    \"\"\"\n",
    "    a = mid - left\n",
    "    b = right - mid\n",
    "    width = right - left\n",
    "\n",
    "    if a >= b:  # driving right off\n",
    "        offset = a / width * LANEWIDTH - LANEWIDTH /2.0\n",
    "    else:       # driving left off\n",
    "        offset = LANEWIDTH /2.0 - b / width * LANEWIDTH\n",
    "\n",
    "    return offset\n",
    "\n",
    "\n",
    "def compute_car_offcenter(ploty, left_fitx, right_fitx, undist):\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    height = undist.shape[0]\n",
    "    width = undist.shape[1]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    bottom_l = left_fitx[height-1]\n",
    "    bottom_r = right_fitx[0]\n",
    "\n",
    "    offcenter = off_center(bottom_l, width/2.0, bottom_r)\n",
    "\n",
    "    return offcenter, pts\n",
    "\n",
    "def create_output(binary_warped, Minv, undist, curvature, offcenter, pts):\n",
    "    ## Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    # Minv = perspective_Minv\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    # Combine the result with the original image\n",
    "    lane_colored = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # img = cv.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "    info_cur = \"Radius of Curvature {:6.1f} m\".format(curvature)\n",
    "    info_pos = \"Vehicle is {:6.1f} m off center\".format(offcenter)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(lane_colored, info_cur, (800,100), font, 0.8, (255,255,255), 1,cv2.LINE_AA)\n",
    "    cv2.putText(lane_colored, info_pos, (800,150), font, 0.8, (255,255,255), 1,cv2.LINE_AA)\n",
    "    \n",
    "    return lane_colored\n",
    "\n",
    "# tracker is the function for fitting polynomials that is started when there was already successfully found a polynomial/line\n",
    "# in a previous frame. A search around the existing polynomial/line is done which is more efficient (kind of targeted search)\n",
    "def tracker(binary_warped, ploty):\n",
    "\n",
    "    #left_fit, right_fit = window_search(left_lane.prev_poly, right_lane.prev_poly, binary_warped, margin=50)\n",
    "    left_fit, right_fit = search_around_poly(left_lane.prev_poly, right_lane.prev_poly, binary_warped)\n",
    "\n",
    "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    std_value = np.std(right_fitx - left_fitx) # np.std computes the standard deviation along the specified axis\n",
    "    if std_value < 21.25:             # test if the left and right line (both detected) are parallel\n",
    "        left_lane.detected = True\n",
    "        right_lane.detected = True\n",
    "        left_lane.current_poly = left_fit\n",
    "        right_lane.current_poly = right_fit\n",
    "        left_lane.current_fitx = left_fitx\n",
    "        right_lane.current_fitx = right_fitx\n",
    "    else:\n",
    "        left_lane.detected = False\n",
    "        right_lane.detected = False\n",
    "        left_lane.current_poly = left_lane.prev_poly\n",
    "        right_lane.current_poly = right_lane.prev_poly\n",
    "        left_lane.current_fitx = left_lane.previous_fitx[-1]\n",
    "        right_lane.current_fitx = right_lane.previous_fitx[-1]\n",
    "\n",
    "\n",
    "def detector(binary_warped, ploty):\n",
    "\n",
    "    #left_fit, right_fit = full_search(binary_warped)\n",
    "    left_fit, right_fit = fit_polynomial(binary_warped)\n",
    "\n",
    "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "    std_value = np.std(right_fitx - left_fitx)\n",
    "    if std_value < 21.25:             # test if the left and right line (both detected) are parallel\n",
    "        left_lane.current_poly = left_fit\n",
    "        right_lane.current_poly = right_fit\n",
    "        left_lane.current_fitx = left_fitx\n",
    "        right_lane.current_fitx = right_fitx\n",
    "        left_lane.detected = True\n",
    "        right_lane.detected = True\n",
    "    else:\n",
    "        left_lane.current_poly = left_lane.prev_poly\n",
    "        right_lane.current_poly = right_lane.prev_poly\n",
    "        if len(left_lane.previous_fitx) > 0:\n",
    "            left_lane.current_fitx = left_lane.previous_fitx[-1]\n",
    "            right_lane.current_fitx = right_lane.previous_fitx[-1]\n",
    "        else:\n",
    "            left_lane.current_fitx = left_fitx\n",
    "            right_lane.current_fitx = right_fitx\n",
    "        left_lane.detected = False\n",
    "        right_lane.detected = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (test images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "#img = mpimg.imread('test_images/signs_vehicles_xygrad.png')\n",
    "#img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "#img = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "#img = mpimg.imread('test_images/test2.jpg')\n",
    "#img = mpimg.imread('test_images/test3.jpg')\n",
    "#img = mpimg.imread('test_images/test4.jpg')\n",
    "#img = mpimg.imread('test_images/test5.jpg')\n",
    "#img = mpimg.imread('test_images/test6.jpg')\n",
    "#img = mpimg.imread('test_images/test_A99Munich_1.jpg')\n",
    "\n",
    "# ATTENTION: If you are using cv2.imread() or the glob API, this will read in a BGR image and you should convert to grayscale\n",
    "# using cv2.COLOR_BGR2GRAY.\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(img), 'with dimensions:', img.shape)\n",
    "plt.imshow(img)  # single color channel image, e.g. gray , call as plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undist = cal_undistort(img, objpoints, imgpoints)\n",
    "plt.imshow(undist)\n",
    "print('This image is:', type(undist), 'with dimensions:', undist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color & Gradient Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_binary = threshold(undist)\n",
    "plt.imshow(img_binary)\n",
    "print('This image is:', type(img_binary), 'with dimensions:', img_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform to \"birds-eye view\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_warped = warp(img_binary, M)\n",
    "plt.imshow(binary_warped)\n",
    "print('This image is:', type(binary_warped), 'with dimensions:', binary_warped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start detector or tracker to find lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "visualization = False\n",
    "# print(left_lane.detected) # DEBUG\n",
    "\n",
    "if left_lane.detected:  # start tracker (am Anfang ist self.detected FALSE >> starts always first with detector\n",
    "    tracker(binary_warped, ploty) # later: Kann nicht das \"top-down\" verwendet werden und die Schritte \"Grayscale\"\n",
    "                                                     # und \"Crop the binary image\" übersprungen werden?\n",
    "else:                   # start detector\n",
    "    detector(binary_warped, ploty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the curvature of the lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over the previous N frames to get the averaged lanes\n",
    "left_lane.process(ploty) # process() is a class function\n",
    "right_lane.process(ploty)\n",
    "\n",
    "# measure the lane curvature\n",
    "curvature = measure_curvature_real(ploty, left_lane.mean_fitx, right_lane.mean_fitx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine vehicle position with respect to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle's off-center in meters\n",
    "offcenter, pts = compute_car_offcenter(ploty, left_lane.mean_fitx, right_lane.mean_fitx, undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_colored = create_output(binary_warped, Minv, undist, curvature, offcenter, pts)\n",
    "plt.imshow(lane_colored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    '''\n",
    "    total pipeline from above as a function\n",
    "    '''\n",
    "    \n",
    "    # distortion correction\n",
    "    undist = cal_undistort(img, objpoints, imgpoints)\n",
    "    \n",
    "    # color & gradient thresholding\n",
    "    img_binary = threshold(undist)\n",
    "    \n",
    "    # perspective transform to \"birds-eye view\"\n",
    "    binary_warped = warp(img_binary, M)\n",
    "    \n",
    "    # start detector or tracker to find the lanes\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    if left_lane.detected:  # start tracker if detection was successfull previously. Then you can do proximity search\n",
    "                            # (search_around_poly()) which is more efficient than a full search (\"fit_polynomial()\")\n",
    "        tracker(binary_warped, ploty)\n",
    "    else:  # start detector. This will always be the case for the very first frame of a video because an initialized lane, \n",
    "            # e.g. \"left_lane = Line()\" by means of the __init__ function of the class, starts with self.detected = False per \n",
    "            # default\n",
    "        detector(binary_warped, ploty)\n",
    "\n",
    "    # average among the previous N frames to get the averaged lanes\n",
    "    left_lane.process(ploty)\n",
    "    right_lane.process(ploty)\n",
    "\n",
    "    # measure the lane curvature\n",
    "    curvature = measure_curvature_real(ploty, left_lane.mean_fitx, right_lane.mean_fitx)\n",
    "    \n",
    "    # compute the car's off-center in meters\n",
    "    offcenter, pts = compute_car_offcenter(ploty, left_lane.mean_fitx, right_lane.mean_fitx, undist)\n",
    "   \n",
    "    # Drawing: combine all images into final video output (only for visualization purpose)\n",
    "    lane_colored = create_output(binary_warped, Minv, undist, curvature, offcenter, pts)\n",
    "        \n",
    "    return lane_colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on project video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'delete/project_video_output.mp4'\n",
    "## To speed up the testing process, one can use pipeline on a shorter subclip of the video with .subclip(start_second,end_second)\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(0,5)\n",
    "clip = clip1.fl_image(process_image) #NOTE: this function expects color images\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on german highway A99 in Munich\n",
    "\n",
    "I wanted to know if this algorithm also runs on videos taken by myself. So, what did I do? I took my wife out on a ... nope, I did not take her out on a date but I took her out on the next motorway from our apartment (isn't that even a better date?). She had to drive the car and I recorded a video of the ride on the highway. Then I tested the algorithm on this video.\n",
    "\n",
    "Note: Before running the pipeline, I had to identify new source points because my video was recorded under different conditions (angles, perspective, etc.). This is why you can find two different source points in my code. Of course, camera calibration needs to be done from scratch.\n",
    "\n",
    "Here is the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_munich = 'delete/A99Munich_output.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/A99Munich.mp4\")\n",
    "clip = clip1.fl_image(process_image) #NOTE: this function expects color images\n",
    "%time clip.write_videofile(output_munich, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_munich = 'A99Munich_output.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_munich))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
